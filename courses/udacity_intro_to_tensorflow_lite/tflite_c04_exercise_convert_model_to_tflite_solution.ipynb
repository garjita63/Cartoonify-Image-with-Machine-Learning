{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garjita63/Cartoonify-Image-with-Machine-Learning/blob/main/courses/udacity_intro_to_tensorflow_lite/tflite_c04_exercise_convert_model_to_tflite_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Eq10uEbw0E4l"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06ndLauQxiQm"
      },
      "source": [
        "# Train Your Own Model and Convert It to TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtav_aq2xh6n"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c04_exercise_convert_model_to_tflite_solution.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_lite/tflite_c04_exercise_convert_model_to_tflite_solution.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka96-ajYzxVU"
      },
      "source": [
        "This notebook uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) datasetâ€”often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing we'll use here.\n",
        "\n",
        "This uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
        "\n",
        "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow. Import and load the Fashion MNIST data directly from TensorFlow:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjOAfhgd__Sp"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pfyZKowNAQ4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f457376d-6c6c-44f8-9243-93e0d3c55633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tadPBTEiAprt"
      },
      "source": [
        "# Download Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jmSkLCyRKqKB"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XcNwi6nFKneZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7d7f11-899d-4b81-a317-4c1d472f3d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset fashion_mnist/3.0.1 (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /root/tensorflow_datasets/fashion_mnist/3.0.1...\u001b[0m\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/fashion_mnist/3.0.1.incompleteF60C1N/fashion_mnist-train.tfrecord\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/fashion_mnist/3.0.1.incompleteF60C1N/fashion_mnist-test.tfrecord\n",
            "\u001b[1mDataset fashion_mnist downloaded and prepared to /root/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "splits, info = tfds.load('fashion_mnist', with_info=True, as_supervised=True, \n",
        "                         split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'])\n",
        "\n",
        "(train_examples, validation_examples, test_examples) = splits\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-eAv71FRm4JE"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hXe6jNokqX3_"
      },
      "outputs": [],
      "source": [
        "with open('labels.txt', 'w') as f:\n",
        "  f.write('\\n'.join(class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iubWCThbdN8K"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAkuq0V0Aw2X"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5SIivkunKCC"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BwyhsyGydHDl"
      },
      "outputs": [],
      "source": [
        "def format_example(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  image = image / 255.0\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HAlBlXOUMwqe"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM4HfIJtnNEk"
      },
      "source": [
        "## Create a Dataset from images and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uxe2I3oxLDhq"
      },
      "outputs": [],
      "source": [
        "train_batches = train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)\n",
        "validation_batches = validation_examples.cache().batch(BATCH_SIZE).map(format_example).prefetch(1)\n",
        "test_batches = test_examples.cache().batch(1).map(format_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-topQaOm_LM"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kDqcwksFB1bh"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(16, 3, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEMOz-LDnxgD"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1fk2faPsjqfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737391b0-2559-4bab-af98-1d37e038bd0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "validation_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DGJe_CNvjnhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7013def6-04c5-4623-e553-d80e54cc137d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_batches, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JGlNoRtzCP4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72154cc-ea25-44e9-f96c-31bbde74a535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 25s 10ms/step - loss: 0.4596 - accuracy: 0.8361 - val_loss: 0.3397 - val_accuracy: 0.8715\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.3005 - accuracy: 0.8921 - val_loss: 0.2837 - val_accuracy: 0.8975\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2557 - accuracy: 0.9070 - val_loss: 0.2503 - val_accuracy: 0.9047\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2233 - accuracy: 0.9181 - val_loss: 0.2642 - val_accuracy: 0.8980\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1919 - accuracy: 0.9283 - val_loss: 0.2388 - val_accuracy: 0.9143\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1666 - accuracy: 0.9385 - val_loss: 0.2308 - val_accuracy: 0.9170\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1430 - accuracy: 0.9469 - val_loss: 0.2472 - val_accuracy: 0.9150\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1255 - accuracy: 0.9536 - val_loss: 0.2446 - val_accuracy: 0.9183\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1067 - accuracy: 0.9600 - val_loss: 0.2952 - val_accuracy: 0.9120\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0877 - accuracy: 0.9677 - val_loss: 0.2808 - val_accuracy: 0.9175\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd00143290>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit(train_batches, \n",
        "          epochs=10,\n",
        "          validation_data=validation_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IeW6kDCgDZ5_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZT9-7w9n4YO"
      },
      "source": [
        "# Exporting to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9dq78KBkCV2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e346b4-3a19-456b-c5ff-206eb5b9fbe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/1/assets\n"
          ]
        }
      ],
      "source": [
        "export_dir = 'saved_model/1'\n",
        "tf.saved_model.save(model, export_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EDGiYrBdE6fl"
      },
      "outputs": [],
      "source": [
        "optimization = tf.lite.Optimize.DEFAULT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RbcS9C00CzGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7406fa6-7fb0-477d-9ce8-6a319a53565e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "converter.optimizations = [optimization]\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "q5PWCDsTC3El"
      },
      "outputs": [],
      "source": [
        "tflite_model_file = 'model.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR6wFcQ1Fglm"
      },
      "source": [
        "# Test the model with TFLite interpreter "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rKcToCBEC-Bu"
      },
      "outputs": [],
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "E8EpFpIBFkq8"
      },
      "outputs": [],
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "test_labels = []\n",
        "test_images = []\n",
        "\n",
        "for img, label in test_batches.take(50):\n",
        "  interpreter.set_tensor(input_index, img)\n",
        "  interpreter.invoke()\n",
        "  predictions.append(interpreter.get_tensor(output_index))\n",
        "  test_labels.append(label[0])\n",
        "  test_images.append(np.array(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kSjTmi05Tyod"
      },
      "outputs": [],
      "source": [
        "#@title Utility functions for plotting\n",
        "# Utilities for plotting\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  img = np.squeeze(img)\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label.numpy():\n",
        "    color = 'green'\n",
        "  else:\n",
        "    color = 'red'\n",
        "    \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(list(range(10)), class_names, rotation='vertical')\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array[0], color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array[0])\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('green')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "cellView": "form",
        "id": "ZZwg0wFaVXhZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "a1560df6-b4e6-410c-96e2-5003d04f43e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "index = 12 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, test_labels, test_images)\n",
        "plt.show()\n",
        "plot_value_array(index, predictions, test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "076bo3FMpRDb"
      },
      "source": [
        "# Download TFLite model and assets\n",
        "\n",
        "**NOTE: You might have to run to the cell below twice**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XsPXqPlgZPjE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "824b07fa-59bc-475c-eae9-8b235eb47555"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_011f9796-59b3-4324-8900-a403c045f524\", \"model.tflite\", 259200)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bc768f93-3164-4c09-9adb-3c1cd67fd88e\", \"labels.txt\", 75)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "\n",
        "  files.download(tflite_model_file)\n",
        "  files.download('labels.txt')\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8t7_jRiz9Vw"
      },
      "source": [
        "# Prepare the test images for download (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Fi09nIps0gBu"
      },
      "outputs": [],
      "source": [
        "!mkdir -p test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sF7EZ63J0hZs"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "for index, (image, label) in enumerate(test_batches.take(50)):\n",
        "  image = tf.cast(image * 255.0, tf.uint8)\n",
        "  image = tf.squeeze(image).numpy()\n",
        "  pil_image = Image.fromarray(image)\n",
        "  pil_image.save('test_images/{}_{}.jpg'.format(class_names[label[0]].lower(), index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "uM35O-uv0iWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f1299f-75c4-4279-a8f2-1149c4de79bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'ankle boot_10.jpg'   coat_40.jpg       sandal_19.jpg\t sneaker_43.jpg\n",
            "'ankle boot_32.jpg'   coat_46.jpg       sandal_2.jpg\t trouser_20.jpg\n",
            "'ankle boot_4.jpg'    coat_48.jpg       sandal_39.jpg\t trouser_22.jpg\n",
            " bag_16.jpg\t      dress_12.jpg      shirt_27.jpg\t trouser_35.jpg\n",
            " bag_17.jpg\t      dress_29.jpg      shirt_33.jpg\t trouser_49.jpg\n",
            " bag_23.jpg\t      dress_37.jpg      shirt_5.jpg\t t-shirt_top_15.jpg\n",
            " bag_34.jpg\t      dress_45.jpg      sneaker_13.jpg\t t-shirt_top_18.jpg\n",
            " bag_36.jpg\t      dress_6.jpg       sneaker_24.jpg\t t-shirt_top_1.jpg\n",
            " bag_3.jpg\t      pullover_28.jpg   sneaker_25.jpg\t t-shirt_top_21.jpg\n",
            " bag_7.jpg\t      pullover_44.jpg   sneaker_26.jpg\t t-shirt_top_47.jpg\n",
            " coat_11.jpg\t      pullover_9.jpg    sneaker_38.jpg\t t-shirt_top_8.jpg\n",
            " coat_30.jpg\t      sandal_0.jpg      sneaker_41.jpg\n",
            " coat_31.jpg\t      sandal_14.jpg     sneaker_42.jpg\n"
          ]
        }
      ],
      "source": [
        "!ls test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "aR20r4qW0jVm"
      },
      "outputs": [],
      "source": [
        "!zip -qq fmnist_test_images.zip -r test_images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tjk4537X0kWN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dddbcbec-665e-46d3-b583-9e49ac08156e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b33f2063-f2b0-4ce8-b1bf-d20b1ed06f01\", \"fmnist_test_images.zip\", 38761)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "try:\n",
        "  files.download('fmnist_test_images.zip')\n",
        "except:\n",
        "  pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tflite_c04_exercise_convert_model_to_tflite_solution.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}